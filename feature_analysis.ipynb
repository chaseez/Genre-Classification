{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It makes sense to drop track_id artist_name and title\n",
    "\n",
    "# TODO\n",
    "# - Normalization/Standardization of most if not all of these features\n",
    "# - Figure out what do do with time_signature, key and mode\n",
    "# - Pop and Classic rock have 15,000 entries while Rap/Hip hop only has 500 or so, we will either need to downsample\n",
    "#   or else make use of synthetic minority oversampling\n",
    "# - Note that loudness has some negative values. This may affect our approach for normalization. We may also need to keep in mind that\n",
    "#   this is probably measured in decibels and is thus logarithmic. \n",
    "#   I believe this won't be a problem as the network can learn non linear relationships\n",
    "\n",
    "# - I will try twice. One dropping the key attribute, one time with it. On a purely musical level the key doesn't mattert\n",
    "#   but it's possible that certain genres use one key more often, and it's possible that the timbre measurements could have some synergy\n",
    "#   with the key in play.\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "df = pd.read_csv('msd_genre_dataset.txt')\n",
    "df_relevant_features = df.drop(columns=[\"track_id\", \"artist_name\", \"title\"])\n",
    "df_relevant_features.head()\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(df_relevant_features.drop(columns=['genre']), df_relevant_features['genre'])\n",
    "\n",
    "# X = df_relevant_features.drop(columns=['key'])\n",
    "\n",
    "#X = pd.get_dummies(X, columns=['time_signature', 'key', 'mode'])\n",
    "X = pd.get_dummies(X_resampled, columns=['time_signature', 'mode'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_resampled)\n",
    "\n",
    "# Now the data is properly encoded and irrelevant variables are gone\n",
    "\n",
    "# Normalize the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Convert normalized features back to a DataFrame for easier inspection\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.19534464 0.09989111 0.06036111 0.04878384 0.04765565 0.04408339\n",
      " 0.03981409 0.03823336 0.03373249 0.03047064 0.02983635 0.02920269\n",
      " 0.0285015  0.02645565 0.02597008 0.02582799 0.02433396 0.02336032\n",
      " 0.0210196  0.01897077]\n",
      "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0 -2.998347  0.335644 -0.680494  1.516816  1.756516 -0.017049 -1.190089   \n",
      "1 -1.776102 -0.457462  1.475422  0.208960  2.258398  1.263633 -0.724537   \n",
      "2  0.874894 -1.013989  1.047119 -0.650188  3.498022 -0.049266  0.464714   \n",
      "3 -3.099636 -0.648593 -0.531658  0.432725 -0.551784  0.379651 -0.080109   \n",
      "4 -2.931069 -1.168187  2.664846 -0.119262  0.007438 -0.096471  0.106467   \n",
      "\n",
      "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
      "0  0.403937  0.523576  0.433837 -1.092615  0.887452 -0.637790 -0.415363   \n",
      "1 -0.336276 -0.282811  0.515409 -1.386272  1.160628 -0.723605  1.037168   \n",
      "2 -0.392122  1.381407  0.831990  0.176645  1.236679 -0.144145 -1.815785   \n",
      "3 -0.892914  0.853403 -0.322482  0.870451 -0.241299  0.194579 -0.529753   \n",
      "4 -0.903190  0.626990 -0.312487  0.364345  0.201329  0.081210 -0.498977   \n",
      "\n",
      "       PC15      PC16      PC17      PC18      PC19      PC20  \n",
      "0  1.175721 -0.457478  0.575669 -0.354118  0.301134 -0.318920  \n",
      "1 -1.068695 -0.533242 -0.516263  0.418085 -1.039948 -0.965357  \n",
      "2  0.358964  0.422181  0.711090  0.308870 -0.653659 -0.999950  \n",
      "3  0.463421 -0.177038  0.077699 -0.313992  0.341088  0.205378  \n",
      "4  0.034114 -0.710728  0.304742  0.411333 -0.154483  0.651455  \n"
     ]
    }
   ],
   "source": [
    "##### PCA #####\n",
    "# Initialize PCA with the desired number of components\n",
    "pca = PCA(n_components=20)  # Adjust the number of components as needed\n",
    "\n",
    "# Apply PCA to the normalized features\n",
    "X_pca = pca.fit_transform(X_normalized_df)\n",
    "\n",
    "# Convert PCA results back to a DataFrame for easier inspection\n",
    "X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i}' for i in range(1, pca.n_components_ + 1)])\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the DataFrame with PCA results\n",
    "print(X_pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's Train This Thing ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized_df, y, test_size=0.2, random_state=None)\n",
    "\n",
    "mlp_clf = MLPClassifier()\n",
    "random_forest_clf = RandomForestClassifier()\n",
    "xgboost_clf = xgb.XGBClassifier()\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4, weights=\"distance\")\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "    ('mlp', mlp_clf),\n",
    "    ('rf', random_forest_clf),\n",
    "    ('xgb', xgboost_clf),\n",
    "    ('knn', knn_clf)\n",
    "], voting='soft', weights=[1, 2, 1, 1])\n",
    "\n",
    "\n",
    "\n",
    "ensemble_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, I know there's some better metrics we can use right?\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Takeaways ###\n",
    "\n",
    "# With a PCA of ten PCs, and an MLP with 100 and 50 layers, we got 50% test accuracy\n",
    "# W/o PCA we got nearly 60%\n",
    "# I bet the low accuracy has something to do with the skewed data, that's probably our next step!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (YourEnvironmentName)",
   "language": "python",
   "name": "yourenvironmentname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
